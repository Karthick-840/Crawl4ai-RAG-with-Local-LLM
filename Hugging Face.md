# Hugging Face Transformers Tutorial

## Introduction
In this tutorial, we will learn how to get started with the Hugging Face Transformers library. This library is one of the most popular NLP libraries in Python and can be integrated with PyTorch or TensorFlow. We'll cover installation, using pipelines, tokenizers, models, saving/loading models, and utilizing the Hugging Face Model Hub.

## Table of Contents
- [00:00 Intro](#0000-intro)
- [00:40 Installation](#0040-installation)
- [01:02 Pipeline](#0102-pipeline)
- [04:37 Tokenizer & Model](#0437-tokenizer--model)
- [08:32 PyTorch / TensorFlow](#0832-pytorch--tensorflow)
- [11:07 Save / Load](#1107-save--load)
- [11:35 Model Hub](#1135-model-hub)
- [13:25 Finetune Introduction](#1325-finetune-introduction)

## 00:00 Intro
Hi everyone, I'm Patrick. In today's video, we will explore the Hugging Face Transformers library, which is highly popular for natural language processing tasks. We'll build a sentiment classification algorithm, look at basic functions, and explore the model hub. Finally, we'll cover how to fine-tune your own model.

## 00:40 Installation
To get started, install either PyTorch or TensorFlow first. Then, install the Transformers library using:

```bash
pip install transformers
